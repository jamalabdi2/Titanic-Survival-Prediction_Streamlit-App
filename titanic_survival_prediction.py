# -*- coding: utf-8 -*-
"""Titanic Survival Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IKajdjp5-QjgCiRiXXUFRedG0ymuWEFH

#**Titanic Survival Prediction**

**Problem Statement**

The competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck



1. survival--->	0 = No, 1 = Yes
2. pclass	Ticket class--->	1 = 1st, 2 = 2nd, 3 = 3rd
3. sex--->	Sex	
4. Age--->	Age in years	
5. sibsp--->	# of siblings / spouses aboard the Titanic	
6. parch--->	# of parents / children aboard the Titanic	
7. ticket--->	Ticket number	
8. fare	--->Passenger fare	
9. cabin--->	Cabin number	
10. embarked--->	Port of Embarkation	C = Cherbourg, Q = Queenstown, S = Southampton

**Download The data from Kaggle Titanic - Machine Learning from Disaster**
"""

#!pip install opendatasets
import opendatasets
dataset_url = 'https://www.kaggle.com/competitions/titanic/data'
opendatasets.download(dataset_url)

"""**Importing all dependencies**"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score,confusion_matrix
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')
sns.set()
import pickle
import joblib

#load data with panda
data_path = '/content/titanic/train.csv'
titanic_data = pd.read_csv(data_path)
titanic_data.head()

# last five rows
titanic_data.tail()

#shape of the dataset
titanic_data.shape

#columns name
titanic_data.columns

# data types
titanic_data.dtypes

#information about the data
titanic_data.info()

# numerical columns
numerical_columns = list(titanic_data.select_dtypes(['int64','float64']).columns)
numerical_columns

#categorical_columns
categorical_columns = list(titanic_data.select_dtypes('object'))
categorical_columns

#numerical columns statistics about the data
titanic_data.describe()

# categorical columns statistics about the data
titanic_data.describe(include='object')

#missing values
titanic_data.isnull().sum()

#impute age missing values with mean
age_mean = titanic_data['Age'].mean()
titanic_data['Age'].fillna(age_mean,inplace=True)

#impute embarked column with mode
embarked_mode = titanic_data['Embarked'].mode()[0]
titanic_data['Embarked'].fillna(embarked_mode,inplace=True)

#drop cabin column
titanic_data = titanic_data.drop('Cabin',axis=1)

titanic_data.isnull().sum()

"""**Data Visualization**"""

#target column
survival = titanic_data['Survived'].value_counts()
survival

survival.values
total_sum  = np.sum(survival.values)
survivors_percentage =round((survival[1]/total_sum)*100,2)
non_survival_percentage =round((survival[0]/total_sum)*100,2)
non_survival_percentage
print(f'Percentage of people who survived: {survivors_percentage}%')
print(f'Percentage of people who did not survived: {non_survival_percentage}%')

plt.subplot(1,2,1),survival.plot(kind='bar'),plt.tight_layout()
plt.subplot(1,2,2),survival.plot(kind='pie',autopct='%.f%%'),plt.tight_layout()
plt.show()

"""**549 people did not survived**

**342 people survived**
"""

numerical_columns

categorical_columns

titanic_data.head()

"""**DATA ANALYSIS**"""

column1 = ['Age','Fare']#histplot,violinplot,boxplot,kdeplot
column2 = ['Survived', 'Pclass', 'SibSp', 'Parch','Sex','Embarked']
#distplot,pie

def column1_plots(df,columns,plot_kind):
  plot_function = {
      'violin':sns.violinplot,
      'box':sns.boxplot,
      'histogram':sns.histplot,
      'kde':sns.kdeplot
        }
  fig = plt.figure(figsize=(8,4))
  for index,column in enumerate(columns):
    axis = fig.add_subplot(1,2,index+1)
    if plot_kind in ['violin','boxplot']:

      plot_function[plot_kind](y=df[column],ax=axis)
      plt.title(f'{plot_kind} plot for {column}')
    else:
      plot_function[plot_kind](df[column],ax=axis)
      plt.title(f'{plot_kind} plot for {column}')

  plt.tight_layout()
  plt.show()

plot_kind = ['violin','box','histogram','kde']
for plot in plot_kind:
  column1_plots(titanic_data,column1,plot)
  print(' ')

column2 = ['Survived', 'Pclass', 'SibSp', 'Parch','Sex','Embarked']

def column2_plot(df,plot_kind,columns):
  plot_function = {
      'hist': plt.hist,
      'bar': plt.bar
  }
  fig = plt.figure(figsize=(12,6))
  for index,column in enumerate(columns):
    axis = fig.add_subplot(2,3,index+1)
    if plot_kind == 'hist':
      plot_function[plot_kind](df[column], bins=20)
      plt.title(f'{plot_kind} for {column}')
    else:
      data = df[column].value_counts()
      labels = data.index
      x = np.arange(len(labels))
      plot_function[plot_kind](x, height=data, tick_label=labels)
      plt.title(f'{plot_kind} plot for {column}')
  plt.tight_layout()
  plt.show()

column2_plot(titanic_data,'hist',column2)
column2_plot(titanic_data,'bar',column2)

#gender who survived
sns.countplot(x='Sex',hue='Survived',data=titanic_data)
plt.show()

"""**many male passengers died and few survived as compared to female**"""

#gender and classes
sns.countplot(x='Sex',hue='Pclass',data=titanic_data)
plt.show()

"""**Majority of male were in third class**

**Data Preprocessing**

**Encoding categorical columns**
"""

column_to_encode = ['Sex','Embarked']
titanic_data.replace({'Sex':{'male':0,'female':1},'Embarked':{'S':0,'C':1,'Q':2}},inplace=True)

titanic_data.head()

#seperate features and target
features = titanic_data.drop(columns =['PassengerId','Name','Ticket','Survived'],axis=1)
target = titanic_data['Survived']

features.head()

#split the data into training, testing data
train_data,test_data,train_labels,test_labels = train_test_split(features,target,stratify=target,test_size=0.2,random_state=2)

"""**Min Max Scalling**"""

scaler = MinMaxScaler()
scaler.fit(train_data)
train_scaled = scaler.transform(train_data)
test_scaled = scaler.transform(test_data)

"""**Modeling**

**Accuracy on training data**

**Base model: LogisticRegression**
"""

log_model = LogisticRegression()
log_model.fit(train_scaled,train_labels)
train_prediction = log_model.predict(train_scaled)
train_accuracy = accuracy_score(train_prediction,train_labels)
train_answer = round(train_accuracy*100,2)
print(f'Accuracy on training data is: {train_answer}%')

"""**Accuracy on test data**"""

test_prediction = log_model.predict(test_scaled)
test_accuracy = accuracy_score(test_prediction,test_labels)
test_answer = round(test_accuracy*100,2)
print(f'Accuracy on testing data is: {test_answer}%')

"""**Confusion Matrix**"""

test_confusionmatrix = confusion_matrix(test_prediction,test_labels)
test_confusionmatrix

"""**Heatmap for sns**"""

sns.heatmap(test_confusionmatrix,annot=True)
plt.title('Confusion Matrix for test prediction')
plt.show()

"""**Try with different models**"""

models = [LogisticRegression(max_iter=1000),SVC(kernel='linear'),RandomForestClassifier(12),KNeighborsClassifier(),XGBClassifier()]
model_results = []

def best_model(models):
  for model in models:
    model.fit(train_scaled,train_labels)
    prediction = model.predict(test_scaled)
    accuracy = accuracy_score(prediction,test_labels)
    formatted_answer = round(accuracy*100,2)
    model_results.append({
        'Name':str(model),
        'Accuracy':formatted_answer
    })
  return pd.DataFrame(model_results).sort_values(by='Accuracy',ascending=False)


best_model(models)

"""**Elbow Method for SVC and Randomforest**"""

scores = []

for i in range(1,150):
  rf = RandomForestClassifier(n_estimators=i,random_state=43)
  rf.fit(train_scaled,train_labels)
  prediction = rf.predict(test_scaled)
  accuracy = accuracy_score(prediction,test_labels)
  scores.append(accuracy)

np.max(scores)

plt.plot(range(1,150),scores)
plt.xlabel("Number of estimators")
plt.ylabel("Accuracy")
plt.title("Random Forest Classifier Accuracy vs. Number of Estimators")
plt.show()



new_model = RandomForestClassifier(12)
new_model.fit(train_scaled,train_labels)
new_prediction = rf.predict(test_scaled)
new_accuracy = accuracy_score(prediction,test_labels)
new_accuracy

confusionmatrix = confusion_matrix(new_prediction,test_labels)
confusionmatrix

"""**Save model**"""

#save the model to a file
joblib.dump(new_model,'RandomForestModel.joblib')
#load using loaded_model = joblib.load(model_name)

with open('Randomforestmodel.pkl','wb') as file:
  pickle.dump(new_model,file)

#load with
#with open('Randomforestmodel.pkl','rb') as file:
  #load = pickle.load(file)